package com.example.emod.Diary

import android.content.Intent
import android.graphics.Outline
import android.os.Bundle
import android.os.Handler
import android.os.Looper
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.tts.TextToSpeech
import android.speech.tts.UtteranceProgressListener
import android.util.Log
import android.util.TypedValue
import android.view.View
import android.view.ViewOutlineProvider
import android.widget.Toast
import androidx.camera.core.CameraSelector
import androidx.camera.core.Preview
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.core.content.ContextCompat
import androidx.fragment.app.activityViewModels
import androidx.lifecycle.lifecycleScope
import com.example.emod.BaseFragment
import com.example.emod.Diary.summary.Summarize1Fragment
import com.example.emod.Diary.viewmodel.SummaryViewModel
import com.example.emod.HomeActivity
import com.example.emod.data.remote.client.ApiClient
import com.example.emod.data.remote.dto.proceed.ProceedRequest
import com.example.emod.data.remote.dto.summary.SummaryRequest
import com.example.emod.data.repository.AuthRepository
import com.example.emod.databinding.FragmentChatBinding
import kotlinx.coroutines.launch
import java.util.Locale

class ChatFragment : BaseFragment<FragmentChatBinding>(FragmentChatBinding::inflate) {

    private val store by lazy { AuthRepository(requireContext()) }
    private val conversation = mutableListOf<String>()
    private var lastQuestion: String? = null
    private var recognizedText: String? = null
    private var isTtsInitialized = false

    private lateinit var tts: TextToSpeech
    private lateinit var speechRecognizer: SpeechRecognizer
    private var pendingSpeechText: String? = null

    // currentStep ê³„ì‚°
    private var currentStep: Int = 1

    // Activity ë²”ìœ„ viewModel
    private val viewModel: SummaryViewModel by activityViewModels()

    // âœ… ApiService ìƒì„± (AuthInterceptor ë°˜ì˜)
    private val api by lazy {
        ApiClient.createApi {
            store.getJwt()
        }
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)

        requireActivity().supportFragmentManager.popBackStack()

        val previewView = binding.imgKidFace

        // previewView ë„ìš°ê¸°
        val cameraProviderFuture = ProcessCameraProvider.getInstance(requireContext())
        cameraProviderFuture.addListener({
            val cameraProvider = cameraProviderFuture.get()
            val preview = Preview.Builder().build().also {
                it.setSurfaceProvider(previewView.surfaceProvider)
            }
            val cameraSelector = CameraSelector.DEFAULT_FRONT_CAMERA

            cameraProvider.unbindAll()
            cameraProvider.bindToLifecycle(this, cameraSelector, preview)
        }, ContextCompat.getMainExecutor(requireContext()))

        // previewView ê²‰ì— ì˜ë¼ë‚´ê¸°
        val radiusPx = TypedValue.applyDimension(
            TypedValue.COMPLEX_UNIT_DIP,
            55f,
            resources.displayMetrics
        )

        previewView.outlineProvider = object : ViewOutlineProvider() {
            override fun getOutline(view: View, outline: Outline) {
                outline.setRoundRect(0, 0, view.width, view.height, radiusPx)
            }
        }
        previewView.clipToOutline = true

        isTtsInitialized = false
        pendingSpeechText = null
        tts = TextToSpeech(requireContext()) { status ->
            if (status == TextToSpeech.SUCCESS) {
                tts.language = Locale.KOREAN
                isTtsInitialized = true

                tts.setOnUtteranceProgressListener(object : UtteranceProgressListener() {
                    override fun onStart(utteranceId: String?) {}
                    override fun onDone(utteranceId: String?) {
                        Handler(Looper.getMainLooper()).post { startSpeechRecognition() }
                    }
                    override fun onError(utteranceId: String?) {}
                })

                // í˜¹ì‹œ ì´ˆê¸°í™” ì „ì— ëŒ€ê¸°ì‹œí‚¨ textê°€ ìˆìœ¼ë©´ ë°”ë¡œ speak
                pendingSpeechText?.let {
                    speakAndStartListening(it)
                    pendingSpeechText = null
                }
            }
        }

        // STT ì´ˆê¸°í™”
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(requireContext())

        // ì²« ì§ˆë¬¸ API í˜¸ì¶œ
        callProceed(emptyList(), 1)

        // "ë‹µë³€ ëë‚´ê¸°" ë²„íŠ¼
        binding.btnFinish.setOnClickListener {
            if (!lastQuestion.isNullOrBlank() && !recognizedText.isNullOrBlank()) {
                conversation.add("assistant: $lastQuestion")
                conversation.add("user: $recognizedText")
                Toast.makeText(requireContext(), "ì§ˆë¬¸ì„ ë³´ëƒˆì–´ìš”!", Toast.LENGTH_SHORT).show()
                Log.d("ChatFragment", "ë³´ë‚´ëŠ” ëŒ€í™”: $conversation")

                // ë²„íŠ¼ ëˆŒë €ì„ ë•Œë§Œ API í˜¸ì¶œ
                callProceed(conversation, currentStep)
            }
        }

        // "ì§ˆë¬¸ ë‹¤ì‹œ ë“£ê¸°" ë²„íŠ¼
        binding.btnAgain.setOnClickListener {
            if (!lastQuestion.isNullOrBlank()) {
                speakAndStartListening(lastQuestion!!)
            } else {
                Toast.makeText(requireContext(), "ë‹¤ì‹œ ë“¤ì„ ì§ˆë¬¸ì´ ì—†ì–´ìš”", Toast.LENGTH_SHORT).show()
            }
        }

        // ë’¤ë¡œê°€ê¸°
        binding.icTurnoff.setOnClickListener {
            val intent = Intent(requireContext(), HomeActivity::class.java)
            startActivity(intent)
        }
    }

    // âœ… proceed API í˜¸ì¶œ
    private fun callProceed(conversation: List<String>, currentStep: Int) {
        lifecycleScope.launch {
            try {
                val response = api.proceed(
                    ProceedRequest(conversation, currentStep)
                )
                Log.d("ChatFragment", "API Response: $response")
                Log.d("ChatFragment", "currentStep: ${currentStep}")

                if (response.isSuccessful) {
                    val body = response.body()
                    Log.d("ChatFragment", "API Body: $body")
                    body?.let {
                        lastQuestion = it.questionToAsk

                        if (!it.isAnswerValid) {
                            // ë‹µë³€ì´ ë¶€ì¡± â†’ ê°™ì€ ì§ˆë¬¸ ë°˜ë³µ
                            binding.tvChatIng.text = it.questionToAsk
                            binding.tvChatIng.visibility = View.VISIBLE
                            binding.tvSequence.text = "${currentStep}ë²ˆì§¸ ì§ˆë¬¸"
                            speakAndStartListening(it.questionToAsk)
                        } else {
                            // ë‹µë³€ì´ ì¶©ë¶„ â†’ ë‹¤ìŒ ì§ˆë¬¸ ì¤€ë¹„
                            lastQuestion = it.questionToAsk

                            // ë§ˆì§€ë§‰ ë‹¨ê³„ ì²´í¬
                            if (it.isAnswerValid && it.nextStep == 5 && currentStep == 4) {
                                Log.d("ChatFragment", "ë§ˆì§€ë§‰ ë‹¨ê³„ ì™„ë£Œ â†’ Summary í˜¸ì¶œ")
                                callSummary()
                            } else if (it.nextStep <= 4) {
                                // ğŸš¨ ì—¬ê¸°ì„œëŠ” callProceedë¥¼ ì¬í˜¸ì¶œí•˜ì§€ ì•Šê³ 
                                // ë‹¤ìŒ ì§ˆë¬¸ì„ UIì™€ TTSë¡œë§Œ ë³´ì—¬ì¤€ë‹¤
                                binding.tvChatIng.text = it.questionToAsk
                                binding.tvChatIng.visibility = View.VISIBLE
                                speakAndStartListening(it.questionToAsk)

                                this@ChatFragment.currentStep = it.nextStep
                            } else {
                                callSummary()
                            }
                        }
                    }
                } else if (currentStep >= 5) {
                    Log.d("ChatFragment", "ë ‰ ë¨¹ì–´ì„œ API ì œëŒ€ë¡œ ì•ˆë¨.")
                    callSummary()
                }
            } catch (e: Exception) {
                Log.e("ChatFragment", "API Exception", e)
            }
        }
    }

    // âœ… Summary API í˜¸ì¶œ
    private fun callSummary() {
        lifecycleScope.launch {
            try {
                val response = api.summary(SummaryRequest(conversation))
                if (response.isSuccessful) {
                    val body = response.body()
                    body?.let {
                        Log.d("ChatFragment", "Summary: $it")

                        // ViewModelì— ë°ì´í„° ì €ì¥
                        viewModel.summaryData.value = it

                        (activity as DiaryActivity).setFragment(Summarize1Fragment())
                    }
                }
            } catch (e: Exception) {
                Log.e("ChatFragment", "Summary API Exception", e)
            }
        }
    }

    // âœ… TTS â†’ ëë‚œ ë’¤ STT ì‹¤í–‰
    private fun speakAndStartListening(text: String) {
        if (isTtsInitialized) {
            val params = Bundle()
            tts.speak(text, TextToSpeech.QUEUE_FLUSH, params, "QUESTION_ID")
        } else {
            // ì•„ì§ TTS ì¤€ë¹„ ì•ˆ ëìœ¼ë©´ textë¥¼ ëŒ€ê¸°íì— ë„£ì–´ë‘”ë‹¤!
            pendingSpeechText = text
            Log.e("ChatFragment", "TTS not initialized yet, sentence queued")
        }
    }

    // âœ… STT (TTS ì´í›„ ìë™ ì‹¤í–‰ë¨)
    private fun startSpeechRecognition() {
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, "ko-KR")
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, false)
        }

        speechRecognizer.setRecognitionListener(object : RecognitionListener {
            override fun onResults(results: Bundle?) {
                val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                recognizedText = matches?.joinToString(" ") ?: ""
//                binding.tvUserInput.text = recognizedText
            }
            override fun onReadyForSpeech(p0: Bundle?) {}
            override fun onRmsChanged(p0: Float) {}
            override fun onBufferReceived(p0: ByteArray?) {}
            override fun onEndOfSpeech() {}
            override fun onError(p0: Int) {}
            override fun onPartialResults(p0: Bundle?) {}
            override fun onEvent(p0: Int, p1: Bundle?) {}
            override fun onBeginningOfSpeech() {}
        })

        speechRecognizer.startListening(intent)
    }

    override fun onDestroyView() {
        super.onDestroyView()
        tts.stop()
        tts.shutdown()
        speechRecognizer.destroy()
    }
}