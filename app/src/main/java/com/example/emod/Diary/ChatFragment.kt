package com.example.emod.Diary

import android.Manifest
import android.content.Intent
import android.graphics.Outline
import android.os.Bundle
import android.os.Handler
import android.os.Looper
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.tts.TextToSpeech
import android.speech.tts.UtteranceProgressListener
import android.util.Log
import android.util.TypedValue
import android.view.View
import android.view.ViewOutlineProvider
import android.view.animation.Animation
import android.view.animation.AnimationUtils
import android.widget.TextView
import android.widget.Toast
import androidx.camera.core.CameraSelector
import androidx.camera.core.Preview
import androidx.camera.lifecycle.ProcessCameraProvider
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.fragment.app.activityViewModels
import androidx.lifecycle.lifecycleScope
import com.example.emod.BaseFragment
import com.example.emod.Diary.summary.Summarize1Fragment
import com.example.emod.Diary.viewmodel.SummaryViewModel
import com.example.emod.HomeActivity
import com.example.emod.R
import com.example.emod.data.remote.client.ApiClient
import com.example.emod.data.remote.dto.proceed.ProceedRequest
import com.example.emod.data.remote.dto.summary.SummaryRequest
import com.example.emod.data.repository.AuthRepository
import com.example.emod.databinding.FragmentChatBinding
import kotlinx.coroutines.launch
import java.util.Locale

class ChatFragment : BaseFragment<FragmentChatBinding>(FragmentChatBinding::inflate) {

    private val store by lazy { AuthRepository(requireContext()) }
    private val conversation = mutableListOf<String>()
    private var lastQuestion: String? = null
    private var recognizedText: String? = null
    private var isTtsInitialized = false

    private lateinit var tts: TextToSpeech
    private lateinit var speechRecognizer: SpeechRecognizer
    private var pendingSpeechText: String? = null
    private lateinit var userChat: TextView
    private lateinit var characterChat: TextView
    private lateinit var anim : Animation

    // currentStep ê³„ì‚°
    private var currentStep: Int = 1

    // Activity ë²”ìœ„ viewModel
    private val viewModel: SummaryViewModel by activityViewModels()

    // âœ… ApiService ìƒì„± (AuthInterceptor ë°˜ì˜)
    private val api by lazy {
        ApiClient.createApi {
            store.getJwt()
        }
    }


    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)

        // userChat, characterChat, anim ì´ˆê¸°í™”
        userChat = binding.tvChatUser
        characterChat = binding.tvChatCharacter
        anim = AnimationUtils.loadAnimation(requireContext(), R.anim.slide_up_fade_out)

        // STT ì´ˆê¸°í™”
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(requireContext())

        speechRecognizer.setRecognitionListener(object : RecognitionListener {
            override fun onResults(results: Bundle?) {
                val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                recognizedText = matches?.joinToString(" ") ?: ""
                Log.d("ChatFragment", "ì¸ì‹ëœ ìŒì„±: ${recognizedText}")
                binding.btnFinish.isEnabled = true
                showTypingChat(userChat, "${recognizedText}")
//                binding.tvUserInput.text = recognizedText
            }
            override fun onReadyForSpeech(p0: Bundle?) {
                Toast.makeText(requireContext(), "ë‹µë³€ì„ ë§í•´ì£¼ì„¸ìš”!", Toast.LENGTH_SHORT).show()
            }
            override fun onRmsChanged(p0: Float) {}
            override fun onBufferReceived(p0: ByteArray?) {}
            override fun onEndOfSpeech() {}
            override fun onError(p0: Int) {
                Log.e("ChatFragment", "STT Error : ${p0}")
            }
            override fun onPartialResults(p0: Bundle?) {}
            override fun onEvent(p0: Int, p1: Bundle?) {}
            override fun onBeginningOfSpeech() {}
        })

        requireActivity().supportFragmentManager.popBackStack()

        val previewView = binding.imgKidFace

        // previewView ë„ìš°ê¸°
        val cameraProviderFuture = ProcessCameraProvider.getInstance(requireContext())
        cameraProviderFuture.addListener({
            val cameraProvider = cameraProviderFuture.get()
            val preview = Preview.Builder().build().also {
                it.setSurfaceProvider(previewView.surfaceProvider)
            }
            val cameraSelector = CameraSelector.DEFAULT_FRONT_CAMERA

            cameraProvider.unbindAll()
            cameraProvider.bindToLifecycle(this, cameraSelector, preview)
        }, ContextCompat.getMainExecutor(requireContext()))

        // previewView ê²‰ì— ì˜ë¼ë‚´ê¸°
        val radiusPx = TypedValue.applyDimension(
            TypedValue.COMPLEX_UNIT_DIP,
            55f,
            resources.displayMetrics
        )

        previewView.outlineProvider = object : ViewOutlineProvider() {
            override fun getOutline(view: View, outline: Outline) {
                outline.setRoundRect(0, 0, view.width, view.height, radiusPx)
            }
        }
        previewView.clipToOutline = true

        isTtsInitialized = false
        pendingSpeechText = null
        tts = TextToSpeech(requireContext()) { status ->
            if (status == TextToSpeech.SUCCESS) {
                tts.language = Locale.KOREAN
                isTtsInitialized = true

                tts.setOnUtteranceProgressListener(object : UtteranceProgressListener() {
                    override fun onStart(utteranceId: String?) {}
                    override fun onDone(utteranceId: String?) {
                        Handler(Looper.getMainLooper()).post { startSpeechRecognition() }
//                        goneChat(characterChat)
                    }
                    override fun onError(utteranceId: String?) {}
                })

                // í˜¹ì‹œ ì´ˆê¸°í™” ì „ì— ëŒ€ê¸°ì‹œí‚¨ textê°€ ìˆìœ¼ë©´ ë°”ë¡œ speak
                pendingSpeechText?.let {
                    speakAndStartListening(it)
                    pendingSpeechText = null
                }
            }
        }


        // ì²« ì§ˆë¬¸ API í˜¸ì¶œ
        callProceed(emptyList(), 1)

        // "ë‹µë³€ ëë‚´ê¸°" ë²„íŠ¼
        binding.btnFinish.setOnClickListener {
            if (!lastQuestion.isNullOrBlank() && !recognizedText.isNullOrBlank()) {
                Log.d("ChatFragment", "í´ë¦­ë¨")
                conversation.add("assistant: $lastQuestion")
                conversation.add("user: $recognizedText")
                Toast.makeText(requireContext(), "ì§ˆë¬¸ì„ ë³´ëƒˆì–´ìš”!", Toast.LENGTH_SHORT).show()
                Log.d("ChatFragment", "ë³´ë‚´ëŠ” ëŒ€í™”: $conversation")

                // ë²„íŠ¼ ëˆŒë €ì„ ë•Œë§Œ API í˜¸ì¶œ
                callProceed(conversation, currentStep)
            }
            binding.btnFinish.isEnabled = false
        }

        // "ì§ˆë¬¸ ë‹¤ì‹œ ë“£ê¸°" ë²„íŠ¼
        binding.btnAgain.setOnClickListener {
            if (!lastQuestion.isNullOrBlank()) {
                speakAndStartListening(lastQuestion!!)
            } else {
                Toast.makeText(requireContext(), "ë‹¤ì‹œ ë“¤ì„ ì§ˆë¬¸ì´ ì—†ì–´ìš”", Toast.LENGTH_SHORT).show()
            }
        }

        // ë’¤ë¡œê°€ê¸°
        binding.icTurnoff.setOnClickListener {
            val intent = Intent(requireContext(), HomeActivity::class.java)
            startActivity(intent)
        }
    }

    private fun setCharacterAnim(anim: AnimationUtils) {
    }

    // âœ… proceed API í˜¸ì¶œ
    private fun callProceed(conversation: List<String>, currentStep: Int) {
        lifecycleScope.launch {
            try {
                val response = api.proceed(
                    ProceedRequest(conversation, currentStep)
                )
                Log.d("ChatFragment", "API Response: $response")
                Log.d("ChatFragment", "currentStep: ${currentStep}")

                if (response.isSuccessful) {
                    val body = response.body()
                    Log.d("ChatFragment", "API Body: $body")
                    body?.let {
                        lastQuestion = it.questionToAsk
                        Log.d("ChatFragment", "LastQuestion : ${lastQuestion}")

                        if (!it.isAnswerValid) {
                            // ë‹µë³€ì´ ë¶€ì¡± â†’ ê°™ì€ ì§ˆë¬¸ ë°˜ë³µ
//                            binding.tvChatCharacter.text = it.questionToAsk
                            binding.tvChatCharacter.visibility = View.VISIBLE
                            speakAndStartListening(it.questionToAsk)
                        } else {
                            // ë‹µë³€ì´ ì¶©ë¶„ â†’ ë‹¤ìŒ ì§ˆë¬¸ ì¤€ë¹„
                            lastQuestion = it.questionToAsk

                            // ë§ˆì§€ë§‰ ë‹¨ê³„ ì²´í¬
                            if (it.isAnswerValid && it.nextStep == 5 && currentStep == 4) {
                                Log.d("ChatFragment", "ë§ˆì§€ë§‰ ë‹¨ê³„ ì™„ë£Œ â†’ Summary í˜¸ì¶œ")
                                callSummary()
                            } else if (it.nextStep <= 4) {
                                // ğŸš¨ ì—¬ê¸°ì„œëŠ” callProceedë¥¼ ì¬í˜¸ì¶œí•˜ì§€ ì•Šê³ 
                                // ë‹¤ìŒ ì§ˆë¬¸ì„ UIì™€ TTSë¡œë§Œ ë³´ì—¬ì¤€ë‹¤
                                binding.tvChatCharacter.text = it.questionToAsk
                                binding.tvChatCharacter.visibility = View.VISIBLE
                                speakAndStartListening(it.questionToAsk)

                                this@ChatFragment.currentStep = it.nextStep

                                when (it.nextStep) {
                                    2 -> binding.bar.setImageResource(R.drawable.bar_2)
                                    3 -> binding.bar.setImageResource(R.drawable.bar_3)
                                    4 -> binding.bar.setImageResource(R.drawable.bar_4)
                                    else -> binding.bar.setImageResource(R.drawable.bar_1) // ê¸°ë³¸ê°’ (ì˜µì…˜)
                                }
                            } else {
                                callSummary()
                            }
                        }
                    }
                } else if (currentStep >= 5) {
                    Log.d("ChatFragment", "ë ‰ ë¨¹ì–´ì„œ API ì œëŒ€ë¡œ ì•ˆë¨.")
                    callSummary()
                }
            } catch (e: Exception) {
                Log.e("ChatFragment", "API Exception", e)
            }
        }
    }

    // âœ… Summary API í˜¸ì¶œ
    private fun callSummary() {
        lifecycleScope.launch {
            try {
                val response = api.summary(SummaryRequest(conversation))
                if (response.isSuccessful) {
                    val body = response.body()
                    body?.let {
                        Log.d("ChatFragment", "Summary: $it")

                        // ViewModelì— ë°ì´í„° ì €ì¥
                        viewModel.summaryData.value = it

                        (activity as DiaryActivity).setFragment(Summarize1Fragment())
                    }
                }
            } catch (e: Exception) {
                Log.e("ChatFragment", "Summary API Exception", e)
            }
        }
    }

    // âœ… TTS â†’ ëë‚œ ë’¤ STT ì‹¤í–‰
    private fun speakAndStartListening(text: String) {
        if (isTtsInitialized) {
            val params = Bundle()
            tts.speak(text, TextToSpeech.QUEUE_FLUSH, params, "QUESTION_ID")
            showTypingChat(characterChat, text)
        } else {
            // ì•„ì§ TTS ì¤€ë¹„ ì•ˆ ëìœ¼ë©´ textë¥¼ ëŒ€ê¸°íì— ë„£ì–´ë‘”ë‹¤!
            pendingSpeechText = text
            Log.e("ChatFragment", "TTS not initialized yet, sentence queued")
        }
    }

    // âœ… STT (TTS ì´í›„ ìë™ ì‹¤í–‰ë¨)
    private fun startSpeechRecognition() {
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, "ko-KR")
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, false)
        }

        Log.d("ChatFragment", "ìŒì„±ì¸ì‹ ì‹œì‘")

        speechRecognizer.startListening(intent)
    }


    // ë‚˜íƒ€ë‚˜ëŠ” ì• ë‹ˆë©”ì´ì…˜
    fun showTypingChat(textView: TextView, message: String) {
        // 1) ì²˜ìŒì—” ìˆ¨ê²¨ë‘ê¸°
        textView.text = ""
        textView.visibility = View.VISIBLE

        // 2) ë“±ì¥ ì• ë‹ˆë©”ì´ì…˜ (fade in + scale in ê°™ì€ íš¨ê³¼)
        val fadeIn = AnimationUtils.loadAnimation(textView.context, R.anim.slide_up_fade_in).apply {
            duration = 300
        }
        textView.startAnimation(fadeIn)

        // 3) íƒ€ì´í•‘ íš¨ê³¼
        val typingDelay: Long = 50 // ê¸€ìë‹¹ ì§€ì—°ì‹œê°„ (ms)
        val handler = Handler(Looper.getMainLooper())

        for (i in message.indices) {
            handler.postDelayed({
                textView.text = message.substring(0, i + 1)
            }, typingDelay * i)
        }

        // 4) (ì„ íƒ) ì¼ì • ì‹œê°„ ë’¤ ì‚¬ë¼ì§€ëŠ” ì• ë‹ˆë©”ì´ì…˜ ì‹¤í–‰
        handler.postDelayed({
            val fadeOutUp = AnimationUtils.loadAnimation(textView.context, R.anim.slide_up_fade_out)
            fadeOutUp.setAnimationListener(object : Animation.AnimationListener {
                override fun onAnimationStart(animation: Animation?) {}
                override fun onAnimationEnd(animation: Animation?) {
                    textView.visibility = View.GONE
                }
                override fun onAnimationRepeat(animation: Animation?) {}
            })
            textView.startAnimation(fadeOutUp)
        }, typingDelay * message.length + 2000) // ë‹¤ íƒ€ì´í•‘ë˜ê³  2ì´ˆ ë’¤ ì‚¬ë¼ì§
    }



    override fun onDestroyView() {
        super.onDestroyView()
        tts.stop()
        tts.shutdown()
        speechRecognizer.destroy()
    }
}